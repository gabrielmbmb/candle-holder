use candle_holder::{Error, Result};
use candle_holder_tokenizers::Tokenizer;

/// A trait for streamers that receives tokens generated by `generate` method using an
/// auto-regressive model. Streamers can be used to
pub trait TokenStreamer<'a> {
    fn put(&mut self, tokens: Vec<Vec<u32>>) -> Result<()>;
}

/// A streamer that reads tokens from a text file and prints them to the console.
pub struct TextStreamer<'a> {
    tokenizer: &'a Box<dyn Tokenizer>,
    skip_special_tokens: bool,
    token_cache: Vec<u32>,
    print_len: usize,
}

impl<'a> TextStreamer<'a> {
    pub fn new(tokenizer: &'a Box<dyn Tokenizer>, skip_special_tokens: bool) -> Self {
        TextStreamer {
            tokenizer,
            skip_special_tokens,
            token_cache: vec![],
            print_len: 0,
        }
    }
}

impl<'a> TokenStreamer<'a> for TextStreamer<'a> {
    fn put(&mut self, tokens: Vec<Vec<u32>>) -> Result<()> {
        if tokens.len() > 1 {
            return Err(Error::msg(
                "`TextStreamer` can only handle one sequence of tokens at a time.",
            ));
        }

        dbg!(tokens.clone());

        self.token_cache.extend(tokens[0].iter());

        let text = self
            .tokenizer
            .decode(&self.token_cache[..], self.skip_special_tokens)?;

        Ok(())
    }
}
